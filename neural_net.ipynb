{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c399f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from read_data import get_dirs\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d81add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"path\"]).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a3129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # change image size\n",
    "    transforms.Resize((224, 224)),\n",
    "    # converts PIL image to PyTorch tensor\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f2ebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 224, 224]) torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "df = get_dirs()\n",
    "\n",
    "# initialising every image transformed\n",
    "dataset = PhotoDataset(df, transform=transform)\n",
    "\n",
    "# data wrapper for convenient usage to model\n",
    "train_loader = DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "# 20 images/labels, 3 colors, 224 height, 224 width\n",
    "# 20 at a time\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a0960c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using:\", device)\n",
    "\n",
    "# resnet18 model with default weights (pre-trained IMAGENET1K_V1)\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# X*W + c, using final layer nodes to output ???\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)   # Alex vs Kelly\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee5964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer on weights using learning rate 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc98640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss = 0.8478, Acc = 0.300\n",
      "Batch 1: Loss = 0.6444, Acc = 0.550\n",
      "Batch 2: Loss = 0.6700, Acc = 0.600\n",
      "Batch 3: Loss = 0.6189, Acc = 0.850\n",
      "Batch 4: Loss = 0.5850, Acc = 0.650\n",
      "Batch 5: Loss = 0.4242, Acc = 0.800\n",
      "Batch 6: Loss = 0.6176, Acc = 0.650\n",
      "Batch 7: Loss = 0.5570, Acc = 0.750\n",
      "Batch 8: Loss = 0.3753, Acc = 0.850\n",
      "Batch 9: Loss = 0.4901, Acc = 0.700\n",
      "Batch 10: Loss = 0.2534, Acc = 0.900\n",
      "Batch 11: Loss = 0.4394, Acc = 0.850\n",
      "Batch 12: Loss = 0.4570, Acc = 0.750\n",
      "Batch 13: Loss = 0.3663, Acc = 0.800\n",
      "Batch 14: Loss = 0.4753, Acc = 0.850\n",
      "Batch 15: Loss = 0.3033, Acc = 0.900\n",
      "Batch 16: Loss = 0.4295, Acc = 0.900\n",
      "Batch 17: Loss = 0.3472, Acc = 0.850\n",
      "Batch 18: Loss = 0.5269, Acc = 0.750\n",
      "Batch 19: Loss = 0.3150, Acc = 0.800\n",
      "Batch 20: Loss = 0.3339, Acc = 0.800\n",
      "Batch 21: Loss = 0.5229, Acc = 0.750\n",
      "Batch 22: Loss = 0.1958, Acc = 1.000\n",
      "Batch 23: Loss = 0.3396, Acc = 0.850\n",
      "Batch 24: Loss = 0.0645, Acc = 1.000\n"
     ]
    }
   ],
   "source": [
    "batch_losses = []\n",
    "batch_accs = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for batch_idx, (imgs, lbls) in enumerate(train_loader):\n",
    "    imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "\n",
    "    # clear old gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # output of model\n",
    "    outputs = model(imgs)\n",
    "\n",
    "    # calculate loss based on current output/weights\n",
    "    loss = criterion(outputs, lbls)\n",
    "\n",
    "    # backward propagation to train model\n",
    "    loss.backward()\n",
    "\n",
    "    # forward propagation to update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    preds = outputs.argmax(dim=1)\n",
    "    acc = (preds == lbls).float().mean().item()\n",
    "\n",
    "    batch_losses.append(loss.item())\n",
    "    batch_accs.append(acc)\n",
    "\n",
    "    print(f\"Batch {batch_idx}: Loss = {loss.item():.4f}, Acc = {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa06aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
